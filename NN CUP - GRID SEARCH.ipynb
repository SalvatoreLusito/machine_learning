{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NN CUP - GRID SEARCH.ipynb","provenance":[],"collapsed_sections":["d4YYXf_art-C","m9yzpT5Mrx9H","6epnzJnIr1ET","T1z62rSIr5as","nxKcePsSr8xk","q_zok1R9ynOp","GnmoSAccsQiC","9rN7jHWP8Ufb","esijrJvjnVsI","81D1Wfpfnagg","UZyCNggSc-vw"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dE52uMUMxfBu","executionInfo":{"status":"ok","timestamp":1629452398920,"user_tz":-120,"elapsed":205,"user":{"displayName":"Salvatore Lusito","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjopQgcONwG7XlH8SVGOPCIA3A9LZSSRkt8CS1whA=s64","userId":"04824523266332244267"}},"outputId":"4ccff992-0980-4445-dc82-bbb369d8e0c1"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0nrhfu_20Udt","executionInfo":{"status":"ok","timestamp":1629452566215,"user_tz":-120,"elapsed":167068,"user":{"displayName":"Salvatore Lusito","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjopQgcONwG7XlH8SVGOPCIA3A9LZSSRkt8CS1whA=s64","userId":"04824523266332244267"}},"outputId":"6dab68ea-5efb-41ec-a922-d9041c503aba"},"source":["import numpy as np\n","import pandas as pd\n","import math\n","# Used to save logs on file\n","import sys\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from tensorflow.keras import layers\n","from tensorflow.keras import initializers\n","from tensorflow.keras import Sequential\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","# Used for L2 regularization\n","from tensorflow.keras import regularizers\n","# Used for dropout\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.layers import Dense\n","from keras.wrappers.scikit_learn import KerasRegressor\n","from tensorflow.keras.optimizers import SGD, Adamax, RMSprop, Adagrad, Adam\n","from sklearn.model_selection import GridSearchCV\n","from keras.constraints import maxnorm\n","from tensorflow.keras.losses import MeanSquaredError\n","\n","from keras import backend as K\n","\n","import tensorflow as tf\n","\n","\n","from datetime import datetime\n","\n","# Used for early stopping\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","from sklearn import preprocessing\n","\n","# Logging\n","log = open(\"NN-grid-CUP-2-P.txt\", \"w\")\n","\n","# Read and view TR\n","# dataset = \"cup/ML-CUP20-TR.csv\"\n","dataset=\"/content/drive/My Drive/Machine Learning Project/CUP/data/ML-CUP20-TR.csv\"\n","\n","# Column 0:     ID\n","# Column 1-10:  inputs\n","# Column 11-12: target_x target_y\n","train_names = [\"id\", \"input_1\", \"input_2\", \"input_3\", \"input_4\", \"input_5\", \"input_6\", \"input_7\", \"input_8\", \"input_9\",\n","               \"input_10\", \"target_x\", \"target_y\"]\n","df_train = pd.DataFrame(pd.read_csv(dataset, sep=',', skiprows=7, header=None, names=train_names, index_col=0))\n","\n","# Store the number of training patterns\n","n_TR_patterns = len(df_train.index)\n","print(f'N. rows TR: {n_TR_patterns}\\n')\n","\n","# log.write(f'N. rows TR: {n_TR_patterns}\\n')\n","\n","# print(df_train.head())\n","\n","# Read and view TS\n","# dataset = \"cup/ML-CUP20-TS.csv\"\n","dataset=\"/content/drive/My Drive/Machine Learning Project/CUP/data/ML-CUP20-TS.csv\"\n","\n","# Column 0:    ID\n","# Column 1-10: inputs\n","test_names = [\"id\", \"input_1\", \"input_2\", \"input_3\", \"input_4\", \"input_5\", \"input_6\", \"input_7\", \"input_8\", \"input_9\",\n","              \"input_10\"]\n","df_test = pd.DataFrame(pd.read_csv(dataset, sep=',', skiprows=7, header=None, names=test_names, index_col=0))\n","\n","# Store the number of (blind) testing patterns\n","n_TS_patterns = len(df_test.index)\n","print(f'N. rows TS: {n_TS_patterns}\\n')\n","\n","# Divide into TR, VL, and (internal) TS\n","attributes = [col for col in df_train.columns if 'input' in col]\n","\n","# Separating internal TS from the rest of training dataset (Hold out ca. 20%)\n","print(\"\\ndf_train \", len(df_train))  # 1524\n","\n","df_subset = df_train.sample(200, random_state=100)\n","print(\"\\ndf_subset \", len(df_subset))  # 304\n","print(df_subset.head())\n","\n","df_train = df_train.drop(df_subset.index)\n","print(\"\\ndf_train after removal \", len(df_train))  # 1220\n","\n","X_train = df_train[attributes].values\n","y_train = df_train[['target_x', 'target_y']].values\n","\n","\n","n_features = X_train.shape[1]\n","print(X_train.shape[0])\n","\n","print(f'\\nN. input features: {n_features}')\n","\n","# log.write(f'\\nN. input features: {n_features}')\n","\n","# Handle (blind) TS\n","attributes = [col for col in df_test.columns if 'input' in col]\n","X_blind_TS = df_test[attributes].values\n","\n","\n","X_test = df_subset[attributes].values\n","y_test = df_subset[['target_x', 'target_y']].values\n","\n","def mee_keras(y_true, y_pred):\n","    return K.mean(K.sqrt(K.sum(K.square(y_true - y_pred), axis=-1, keepdims=True)))\n","\n","from sklearn.metrics import make_scorer\n","my_func = make_scorer(mee_keras, greater_is_better=False)\n","\n","\n","def r2_keras(y_true, y_pred):\n","    ss_res = K.sum(K.square(y_true-y_pred))\n","    ss_tot = K.sum(K.square(y_true - K.mean(y_true)))\n","    return 1 - ss_res/(ss_tot + K.epsilon())\n","\n","\n","def build_model(neurons=1, dropout_rate=0.0, weight_constraint=0, activation='sigmoid', learn_rate=0.001, momentum=0,\n","                reg_value=0, optimizer='adam', init_mode='uniform'):\n","    tf.keras.backend.clear_session()\n","    # Build the model\n","    model_1 = Sequential()\n","\n","    if reg_value != 0:\n","        # Apply regularization\n","        layer_1 = Dense(neurons, input_dim=n_features, activation=activation,\n","                        kernel_initializer=init_mode,\n","                        kernel_constraint=maxnorm(weight_constraint),\n","                        kernel_regularizer=regularizers.l2(reg_value),\n","                        bias_regularizer=regularizers.l2(reg_value), )\n","        layer_2 = Dense(neurons, activation=activation,\n","                        kernel_initializer=init_mode,\n","                        kernel_constraint=maxnorm(weight_constraint),\n","                        kernel_regularizer=regularizers.l2(reg_value),\n","                        bias_regularizer=regularizers.l2(reg_value), )\n","        layer_3 = Dense(2, activation='linear')\n","    else:\n","        # No regularization\n","        layer_1 = Dense(neurons, input_dim=n_features, activation=activation)\n","        layer_2 = Dense(neurons, activation=activation)\n","        layer_3 = Dense(2, activation='linear')\n","\n","    model_1.add(layer_1)\n","\n","    if dropout_rate != 0:\n","        # Add dropout, seed for reproducibility\n","        model_1.add(Dropout(dropout_rate, seed=123))\n","\n","    model_1.add(layer_2)\n","\n","    if dropout_rate != 0:\n","        # Add dropout, seed for reproducibility\n","        model_1.add(Dropout(dropout_rate, seed=123))\n","\n","    model_1.add(layer_3)\n","\n","    # Compile the model\n","    if optimizer == 'SGD':\n","        # opt = SGD(learning_rate=learn_rate, momentum=momentum)\n","        # With clipping\n","        opt = SGD(learning_rate=learn_rate, momentum=momentum, clipnorm=1.0)\n","    elif optimizer == 'Adamax':\n","        # opt = Adamax(learning_rate=learn_rate, name=\"Adamax\")\n","        # With clipping\n","        opt = Adamax(learning_rate=learn_rate, name=\"Adamax\", clipnorm=1.0)\n","    elif optimizer == 'RMSprop':\n","        # With clipping\n","        opt = RMSprop(learning_rate=learn_rate, rho=0.9, momentum=momentum,\n","                      epsilon=1e-07, centered=False, name=\"RMSprop\", clipnorm=1.0)\n","    elif optimizer == 'Adagrad':\n","        # With clipping\n","        opt = Adagrad(learning_rate=learn_rate, initial_accumulator_value=0.1,\n","                      epsilon=1e-07, name=\"Adagrad\", clipnorm=1.0)\n","    else:\n","        # Adam\n","        # With clipping\n","        opt = Adam(learning_rate=learn_rate, beta_1=0.9, beta_2=0.999,\n","                   epsilon=1e-07, amsgrad=False, name=\"Adam\", clipnorm=1.0)\n","\n","    # Metrics: MSE, MEE (manual implementation), R^2 (manual implementation)\n","    model_1.compile(loss=MeanSquaredError(), optimizer=opt,\n","                    metrics=[tf.keras.metrics.MeanSquaredError(), mee_keras, r2_keras])\n","\n","    return model_1\n","\n","\n","# HYPER-PARAMETER TUNING\n","model = KerasRegressor(build_fn=build_model, verbose=0)\n","\n","learn_rate = [0.1]\n","momentum = [0.1]\n","optimizer = ['SGD']\n","init_mode = ['he_uniform']\n","batch_size = [50]\n","epochs = [500]\n","weight_constraint = [1]\n","dropout_rate = [0.0]\n","neurons = [300]\n","activation = ['tanh']\n","reg_value = [0.01]\n","\n","\n","# datetime object containing current date and time\n","print('\\ninizio:', datetime.now())\n","\n","param_grid = dict(neurons=neurons, dropout_rate=dropout_rate, weight_constraint=weight_constraint, optimizer=optimizer,\n","                  batch_size=batch_size, epochs=epochs, learn_rate=learn_rate, momentum=momentum, init_mode=init_mode,\n","                  activation=activation, reg_value = reg_value)\n","grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=5, cv=3, scoring='neg_mean_squared_error')\n","\n","grid_result = grid.fit(X_train, y_train)\n","\n","print('\\nfine:', datetime.now())\n","\n","print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n","\n","means = grid_result.cv_results_['mean_test_score']\n","stds = grid_result.cv_results_['std_test_score']\n","params = grid_result.cv_results_['params']\n","for mean, stdev, param in zip(means, stds, params):\n","    print(\"%f (%f) with: %r\" % (mean, stdev, param))"],"execution_count":36,"outputs":[{"output_type":"stream","text":["N. rows TR: 1524\n","\n","N. rows TS: 472\n","\n","\n","df_train  1524\n","\n","df_subset  200\n","       input_1   input_2   input_3  ...  input_10   target_x   target_y\n","id                                  ...                                \n","801   1.155300  0.059795 -0.604900  ...  1.727382  39.929663 -29.595517\n","720  -0.918605  0.637450  1.347002  ... -0.903759  72.384610 -28.855841\n","1059 -0.652593  1.394323  0.103282  ... -1.030427  52.796461 -39.445597\n","189   1.439956 -0.605409 -0.758339  ...  1.819379  40.553341 -30.551312\n","229   0.915644 -1.250489 -1.028318  ...  0.055362  31.467524 -13.706777\n","\n","[5 rows x 12 columns]\n","\n","df_train after removal  1324\n","1324\n","\n","N. input features: 10\n","\n","inizio: 2021-08-20 09:39:59.030991\n","\n","fine: 2021-08-20 09:42:45.522999\n","Best: -9.035889 using {'activation': 'tanh', 'batch_size': 50, 'dropout_rate': 0.0, 'epochs': 500, 'init_mode': 'he_uniform', 'learn_rate': 0.1, 'momentum': 0.1, 'neurons': 300, 'optimizer': 'SGD', 'reg_value': 0.01, 'weight_constraint': 1}\n","-9.035889 (0.719459) with: {'activation': 'tanh', 'batch_size': 50, 'dropout_rate': 0.0, 'epochs': 500, 'init_mode': 'he_uniform', 'learn_rate': 0.1, 'momentum': 0.1, 'neurons': 300, 'optimizer': 'SGD', 'reg_value': 0.01, 'weight_constraint': 1}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HJf6C7Te2ccI","executionInfo":{"status":"ok","timestamp":1629452566216,"user_tz":-120,"elapsed":6,"user":{"displayName":"Salvatore Lusito","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjopQgcONwG7XlH8SVGOPCIA3A9LZSSRkt8CS1whA=s64","userId":"04824523266332244267"}},"outputId":"cbc76f32-27ca-43f2-c372-75baa6f4e8e5"},"source":["best_grid = grid.best_estimator_\n","\n","ypred = best_grid.predict(X_test)\n","\n","mse = mean_squared_error(y_test, ypred)\n","mee = mee_keras(y_test, ypred)\n","print(\"MSE on test set: \", mse)\n","print(\"MEE on test set: \", float(mee))"],"execution_count":37,"outputs":[{"output_type":"stream","text":["MSE on test set:  7.0344479597085146\n","MEE on test set:  3.0564269207791015\n"],"name":"stdout"}]}]}